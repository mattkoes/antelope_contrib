<chapter Foreign Data Formats>

<subsection Exporting Data from Datascope Database>
<commands>
autodrm [options] [files]
    Antelope IDC/GSE2.1 AutoDRM Server
<options>
-d	debug: print output to stderr rather than sending mail
-D dir	run in directory dir
-p pf	use parameter file pf
-v	more verbose
</options>

private autodrm_wrapper
    script which is run by sendmail to run autodrm

dbresp2autodrm view
    convert response information from view to autodrm format

rtbulletin [-Av] [-s subset] aview [t0 [t1|period]]
    create a bulletin from input view aview (-A causes standard autodrm output)

db2ah [options] dbin dbout
    convert css waveform files into ah format
<options>
-sc	sta_chan
-ts	start time
-te	end time
-w	wfdir
-gap	{ none | zero | interp }
-counts
-h	help
-v	version
</options>

private db2ew_wave_server [-vV] [-p pf] dbname
    attach to a CSS3.0 database and make data
    therein accessible via the Earthworm protocols.

db2ims [options] db
    create IMS1.0 short DMC format bulletin
<options>
-d db	database containing dmcbull table 
-e time	origin end time
-l file	output log file name
-m	report magnitudes (unprogrammed)
-p pf	use paramter file pf
-s time	origin start time
-t time	exclude origins with lddate before time
-v	verbose
-V	very verbose
-y	only report reviewed origins
</options>

ims2dmc [options] file db
    send IMS1.0 short files to DMC and track in db
<options>
-C dir	product directory
-m list	email address list
-o orb	orb for orbxfer transfer of files
-s subject	subject line of email
-v	verbose
-V	more verbose than you want
</options>

mk_dmc_files [options] {-D | -V vnet} dbin dbtrack [comment]
    generate dataless SEED or VND and optionally export to others
<options>
-v	verbose
-z	use gzip to compress output file
-p pf	parameter file
-d dir	output directory for files
-C dir	leading dir for output directory
-N net	network code for output file
-s sta	station for single station dataless
-f file	override default file name
-o orb	output orb for orbxfer2(1)
-D	generate dataless SEED
-V vnet	generate VND file for vnet
</options>

db2sac [options] dbin dbout
    convert css waveform files into sac format
<options>
-i	intel order output
-sc sta/chan	select sta/chan pairs with dbpick style pseudo-glob
-ts t0	starting at time t0
-te t1	ending at time t1
-w wfdir	write waveform files into wfdir (default "sac")
-gap {none|zero|interp}	
	handle gaps according to rule (default zero)
-counts	keep output waveform in counts (don't apply calib)
</options>



db2segy db outfile [-pf pf] [-v]
    convert waveforms from input database db to segy disk image

deployment2vnd [options] db file
    convert deployment table to CSV or tab format VND table 
<options>
-h	print headers	
-s subset	subset expression
-t	use tabs instead of commas
-v	verbose
</options>

<subsection Importing Data into a Datascope Database>
<commands>
aah2db [-vV] ahfile [ahfile...] dbname
    convert non-XDR AH files to database

ah2db ah1 [ah2 .. ] dbout
    create CSS database dbout from AH format waveform files ah1, ah2, ...

altusevt2db evtfilename [dbname sta n1=chan1 [n2=chan2 [...]]]
     read Kinemetrics EVT file format and convert to a database

autodrm2db [-vV] reply1 [reply2 ..] dbout
    read autoDRM replies reply1, reply2, ... and copy into output database dbout

gnis2db gnis_file dbname [State]
     convert GNIS feature-name files to database

grdinfo2db [-n name] [-t type] gridfile dbname
     add GMT grid-file information to database

deprecated isc2db [-c] [-p] [-s start] [-e end] isc_bulletin dbout
    read ISC bulletin from NEIC CD into CSS database dbout

deprecated pde2origin pde dbout [-auth author]
    create origin records in database dbout from input PDE file pde

deprecated qed2origin qed dbout
    create origin records in database dbout from input QED file qed

logs2dlevent [options] logdir db
    create dlevent records in db from q330 log files
<options>
-p pf	alternate pf file
-d time	start time for review
-n ndays	total number of days to review	
-v	verbose
-l match_log	regex for files to search
</options>

mk_dbops { -I | -R | -A } [options] dbopsdb snet sta timestamp [comm_provider [comm_type]]
<options>
-I	installation, type of update
-R	removal, type of update
-A	adoption, type of update	
-k	keep backup files
-n	don't update tables
-v	verbose
-V vnet	Virtual Network Definition code
-p pf
-m match	pkt source match
-P prelim_orb	
-S status_orb
-C cmd_orb
-w prelim_wfDB
-W wfDB
-s siteDB
</options>


pick2db [-cvp] [-r reference_db[:reference_db...]] pickfile [pickfile...] dbname
    convert hypoellipse pickfile(s) to CSS3.0 database
<options>
-c	attempt to fake channel names
-v	verbose
-p	put component code into channel field
-r reference_db[:reference_db...]]
 	add references to other databases in descriptor file
</options>

reb2db filename [filename ...] db
    convert Reviewed Event Bulletins of GSE2.0, IMS1.0, or IMS1.0:SHORT format to CSS3.0 database db

ref2db [options] input dbname [start-time [end-time]]
    convert data in REFTEK format to css3.0
<options>
-d datatype	specify waveform datatype
-e	create files based on RefTek event start and end time
-l	create logfile containing instrument status information
-m das	copy only packets with serial number das
-p pf	specify parameter file to match das to station name
-s size	default segmentation of waveforms
-n net	specify miniseed network
-v	print srcname and time of every packet read
-w	do not save waveform data; used to extract log file or get gap info
</options>

deprecated psd2db [options] sd dbout
    read PASSCAL SEED volume sd and produce tables wfdisc, sensor, site, sitechan, and instrument in database dbout
<options>
-n	require that dbout database contain no records
-w	only create wfdisc table
-t tolerance
-respdir dir1	use directory dir1 for response files
-stagedir dir2
 	also create stage table, using directory dir2 for stage table response files
-v	more verbose
</options>

sac2db [-v] sac1 [sac2 ... ] dbout
    create wfdisc, site, sitechan (and possibly origin, event, arrival and assoc records) in output database dbout from SAC files sac1, sac2 ...

sachd [sac1 ...]
    print header information from SAC files sac1, ...

scec2db [options] dbname
    retrieval and conversion of SCEC bulletin
<options>
-v	verbose
-d	retrieve one day
-w	retrieve one week
-m	retrieve one month
-f 	file
-s	start_time
-e 	end_time
-c	{catread|scecdc|hypo71|hypo2000}
</options>

segy2css [-event] [-ftbl] fname ..
    convert PASSCAL SEGY format data to CSS format

Xphase2db db [-phase name]
    convert an input Xphase pick file to css3.0 arrivals

<subsection Seed and Miniseed>
<commands>

deprecated chk_miniseed [-v] miniseed ...
    inspects miniseed files for blocks where net, sta, chan, or loc don't match first block and for blocks where times are out of order.

db2miniseed [options] db [output]
    create miniseed from input database
<options>
-r size	specify record size (default 4096)
-l {1|2}	specify steim compression level (default 2)
-n net	specify default network
-v	verbose
</options>

db2sd [-cv] [-n net] [-l lbl] db sd
    create SEED volume sd from database db (db must contain affiliation, network, sensor, site, stage, calibration and wfdisc tables)

fix_miniseed [-ifv] [-d db] [-{p|P} pf] miniseed|dir ...
    change network, station, channel and/or location codes in specified miniseed volumes or all miniseed found under specified directories

log2miniseed [-avV] [-c chan] [-l loc] [-n net] [-s sta] log ...
     read input log files and create miniseed

miniseed2db [-T tolerance] [-v] miniseed|dir [msd2|dir2 ...] db
    create wfdisc rows in db for miniseed volume(s), or miniseed volumes under directories

miniseed2orb [options] file|directory ... orb
    put data blocks from input miniseed files into packets on orb
<options>
-s start	start-time
-e endtime 	end time
-I 	inclulsive time screening 
-m re 	keep if net_sta_chan_loc matches re
-r re 	reject if net_sta_chan_loc matches re
-d db 	look up correct sta/chan in calibration table
-p pf 	alternate parameter file
-u	don't add /@ suffix to srcnames
-v 	more verbose
</options>

miniseed2days [options] miniseed ...
    separate input miniseed into separate channel day volumes
<options>
-C file	chuck blocks with bad time or compress errors into file
-d db 	create output db by running miniseed2db on output files
-D 	retain duplicate seed blocks in output
-f 	ignore mixed block size and out of time order miniseed errors 
-I 	inclulsive time screening 
-S dir	alternate output directory
-e end	ignore data after endtime
-k 	keep input data blocks with poor timing quality
-m match	only keep net_sta_chan_loc matching this re
-r reject	reject net_sta_chan_loc matching this re
-s start	ignore data before start
-U	eliminate consecutive duplicate data blocks on input
-u	eliminate all duplicate data blocks from input
-v	more verbose
-w wfname	alternate pattern for output file names
</options>

private mk_dataless_wfdisc [-v] [-p pf] dbin
    make fake wfdisc file in order to create dataless seed file

private trash_data [-inv] sd 
    truncate SEED volume sd following station headers, creating dataless SEED volume

mk_dataless_seed [-n re] [-o dataless_seed] [-p pf] [-s re] [-vk] db
    create dataless seed volume from db, optionally using only stations which match -n net and/or -s sta regular expression

mk_dmc_seed [-nvV] [-l secs] [-r days] [-M maxmem] [-m email] [-s stime] [-t tape] [-d dir] rt_db
    build IRIS DMC files on tape or disk

msdd [-bdhovx] [-n max] miniseed ...
    dump miniseed volume; -o shows opaque blockettes 

msdd -i miniseed 
    interactive mode for inspecting miniseed

patch_miniseed [-nvv] miniseed ...
    look for and fix bad reverse integration constants, unless -n

qtunbale [options] url [time [endtime|period]]
    unload data from Quanterra baler
<options>
-a	just show time range available
-c chan	only channel chan (??-???)
-d db	make wfdisc with miniseed2db
-f w	size of time window for requests
-i info	where to save info files from baler
-o orb	pass directly to orb using miniseed2orb
-q	wait quietly for baler to wake up
-Q	don't ping baler
-r	raw output, no miniseed2days or miniseed2orb
-S dir	subdirectory for miniseed day files
-t to	timeout for ping response from baler
-u 	show all URLs used
-v	more verbose
-w wfname	specify pattern for miniseed files
</options>

qtunbale2 [options] url [time [endtime|period]]
	like qtunbale, but using wget instead of perl http

deprecated sd2db [options] sd dbout
    read SEED volume sd and produce tables wfdisc, sensor, site, sitechan, and instrument in database dbout
<options>
-d	print out each blockette as it is read
-f n	skip to file n (of input tape)
-c n	read just n files from input tape
-i	create wfdisc and extract wave form data without using other header information
-r dir	save response files in directory dir
-s	sweep identical time adjacent tuples into single tuple
-S stachan	extract waveforms only for station/channel pairs matching dbpick style pseudo-glob stachan
-t	don't create wfdisc table
-v	print summary of blockettes read and processed
-w dir	save waveforms in directory dir
-x id	write entries in seedindex table showing stations and time range contained on tape id
-z	compress waveform files (using compress(1)) after they are complete
</options>

sdd [-sv] sd
    dump blockettes (summary only if -s) from SEED volume sd

seed2db [options] seed [db]
    read SEED volume seed, produce validation commentary and optionally database tables 
<options>
-lsize	size	specify logical record size
-vvv		be increasingly verbose
-respdir rdir	save responses into rdir
-stagedir sdir  create stage table; save stage responses into sdir
-chansift pf	select specific sta/chan pairs through pf
-tstart t0	start at time t0
-tend   t1	stop at time t1
-nodata		create no wfdisc table
-nodataless	only create wfdisc
-nofirerrors	shut up about fir errors
</options>

seeddump [-lsize sz] [-types list] [-v[v]] [-sta] seed
    dump certain blockettes from seed according to tlist:
    (V=Volume, A=Abbreviation, S=Station, T=Time span, D|R|Q=Data)
